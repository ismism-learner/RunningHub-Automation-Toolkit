#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import requests
import json
import re
import time
from datetime import datetime
from typing import List, Tuple, Optional, Dict, Any

# ==================== é…ç½®åŒºåŸŸ ====================

# VVVVVV ã€ç”¨æˆ·åªéœ€è¦ä¿®æ”¹å’Œç²˜è´´ curl å‘½ä»¤çš„åœ°æ–¹ã€‘ VVVVVV
CURL_COMMAND_TEMPLATE = """

"""
# ^^^^^^ ã€ç”¨æˆ·åªéœ€è¦ä¿®æ”¹å’Œç²˜è´´ curl å‘½ä»¤çš„åœ°æ–¹ã€‘ ^^^^^^

BASE_URL = "https://www.runninghub.cn"
UPLOAD_URL = f"{BASE_URL}/task/openapi/upload"
WORKFLOW_URL = f"{BASE_URL}/task/openapi/ai-app/run"

# åŠ¨æ€é…ç½®å˜é‡
WEBAPP_ID = None
API_KEY = None
WORKFLOW_NODE_TEMPLATE = None 
BATCH_SIZE = 0     
IMAGE_STRIDE = 1   

# æ—¥å¿—æ–‡ä»¶è·¯å¾„
ERROR_LOG_FILE = 'error_log.txt'

# ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
WAIT_TIME = 60
RETRY_WAIT_TIME = 30
WORKFLOW_RETRY_COUNT = 6

# ==================== æç¤ºè¯å¤„ç†å‡½æ•° (æ–°å¢/ä¿®æ”¹) ====================

def get_combined_txt_content() -> str:
    """
    è¯»å–å½“å‰ç›®å½•ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶çš„å†…å®¹å¹¶åˆå¹¶ï¼Œä¸è¿›è¡Œè§£æã€‚
    ç”¨äºï¼š1. Image æ¨¡å¼ä¸‹çš„é€šç”¨ Promptï¼› 2. T2I æ¨¡å¼ä¸‹çš„æ‰¹æ¬¡è§£æã€‚
    """
    prompt_text = ""
    txt_files = sorted([f for f in os.listdir('.') if os.path.isfile(f) and f.lower().endswith('.txt')])
    
    if not txt_files:
        return ""
    
    print("\n[æç¤ºè¯] å‘ç°ä»¥ä¸‹ TXT æ–‡ä»¶:")
    for txt_file in txt_files:
        try:
            with open(txt_file, 'r', encoding='utf-8') as f:
                content = f.read()
                prompt_text += content + "\n"
                print(f"  - è¯»å– {txt_file} æˆåŠŸ")
        except Exception as e:
            print(f"  âœ— è¯»å– {txt_file} å¤±è´¥: {e}")
            log_error("FileRead", f"æ— æ³•è¯»å– TXT æ–‡ä»¶: {txt_file}", {"exception": str(e)})
            
    return prompt_text.strip()


def parse_prompt_batches(combined_content: str) -> List[str]:
    """
    æ ¹æ® '=== ç»„åˆæç¤ºè¯ - NO. X ===' æ¨¡å¼è§£æå‡ºæç¤ºè¯æ‰¹æ¬¡åˆ—è¡¨ã€‚
    """
    if not combined_content:
        return []
        
    # æ­£åˆ™è¡¨è¾¾å¼ï¼šåŒ¹é…å¼€å¤´ï¼Œå¹¶åœ¨åŒ¹é…çš„æ ‡è®°å¤„è¿›è¡Œåˆ†å‰²
    # \s* åŒ¹é…å¯é€‰çš„ç©ºç™½ç¬¦
    pattern = re.compile(r'^\s*=== ç»„åˆæç¤ºè¯ - NO\.\s*\d+\s*===\s*', re.MULTILINE)
    
    # 1. ä»¥æ ‡è®°åˆ†å‰²å†…å®¹
    sections = pattern.split(combined_content)
    
    # 2. è¿‡æ»¤æ‰åˆ†å‰²åçš„ç©ºå­—ç¬¦ä¸²ï¼ˆé€šå¸¸æ˜¯æ–‡ä»¶å¼€å¤´çš„éƒ¨åˆ†ï¼‰ï¼Œåªä¿ç•™å®é™…çš„æç¤ºè¯å†…å®¹
    prompt_list = [s.strip() for s in sections if s.strip()]
    
    return prompt_list


# ==================== é€šç”¨å·¥å…·å‡½æ•° (ä¸å˜) ====================

def log_error(error_type: str, message: str, details: Optional[Dict[str, Any]] = None):
    """è®°å½•é”™è¯¯æ—¥å¿—åˆ° error_log.txt æ–‡ä»¶ã€‚"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] [{error_type} ERROR]\n"
    log_entry += f"  Message: {message}\n"
    if details:
        log_entry += "  Details:\n"
        for key, value in details.items():
            value_str = str(value)
            if len(value_str) > 200:
                value_str = value_str[:200] + "..."
            log_entry += f"    - {key}: {value_str}\n"
    log_entry += "-" * 50 + "\n"
    try:
        with open(ERROR_LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(log_entry)
        print(f"  [æ—¥å¿—è®°å½•] é”™è¯¯å·²å†™å…¥ {ERROR_LOG_FILE}")
    except Exception as e:
        print(f"  [æ—¥å¿—å¤±è´¥] å†™å…¥é”™è¯¯æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

def parse_curl_command(curl_string: str) -> Dict[str, Any]:
    """è§£æ curl å‘½ä»¤å­—ç¬¦ä¸²ï¼Œæå– JSON è´Ÿè½½ï¼Œå¹¶ä¿®å¤å¤åˆ¶ç²˜è´´å¯¼è‡´çš„éšè—å­—ç¬¦é—®é¢˜ã€‚"""
    match = re.search(r'--data-raw\s+\'(.+?)\'|--data\s+\'(.+?)\'', curl_string, re.DOTALL)
    if not match:
        raise ValueError("æ— æ³•åœ¨ curl å‘½ä»¤ä¸­æ‰¾åˆ° --data-raw æˆ– --data éƒ¨åˆ†ã€‚")
    json_string = match.group(1) or match.group(2)
    json_string = json_string.replace('\n', '').replace('\\', '')
    json_string = json_string.replace('\xa0', ' ').replace('\u3000', ' ').strip()
    try:
        return json.loads(json_string)
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(f"æ— æ³•è§£ææå–çš„ JSON è´Ÿè½½: {e}.", e.doc, e.pos)

def determine_processing_logic(node_template: List[Dict[str, Any]]) -> Tuple[int, int]:
    """ç¡®å®šæ‰¹æ¬¡å¤§å°å’Œåºåˆ—æ­¥é•¿ã€‚"""
    image_nodes = [node for node in node_template if node.get("fieldName") == "image"]
    batch_size = len(image_nodes)
    if batch_size == 0: stride = 0 
    elif batch_size == 1: stride = 1
    elif batch_size == 2: stride = 1
    elif batch_size == 3: stride = 2
    else: stride = batch_size 
    print(f"**å¤„ç†é€»è¾‘ç¡®å®š:**")
    print(f"  - æ¯ä¸ªä»»åŠ¡å›¾ç‰‡æ•° (Batch Size): {batch_size}")
    print(f"  - åºåˆ—æ­¥é•¿ (Stride): {stride}")
    return batch_size, stride

def natural_sort_key(s):
    """åˆ›å»ºä¸€ä¸ªæ’åºé”®ï¼Œå°†æ–‡ä»¶åä¸­çš„æ•°å­—è§†ä¸ºæ•°å­—ï¼Œå®ç°è‡ªç„¶æ•°å­—æ’åºã€‚"""
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split('([0-9]+)', s)]

def get_image_files_categorized() -> Tuple[List[str], List[str], Dict[int, str], Optional[str]]:
    """è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œå¹¶æ ¹æ®å‰ç¼€ '#'ã€'##' æˆ– '###' è¿›è¡Œåˆ†ç±»ã€‚"""
    extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']
    all_files = []
    for f in os.listdir('.'):
        if os.path.isfile(f):
            ext = os.path.splitext(f)[1].lower()
            if ext in extensions:
                all_files.append(f)
    
    sorted_all_files = sorted(all_files, key=natural_sort_key)
    sequential_files = []
    fixed_files_map: Dict[int, str] = {} 
    
    for f in sorted_all_files:
        filename_without_ext = os.path.splitext(f)[0]
        fixed_pos = 0 
        
        if filename_without_ext.startswith('###'): fixed_pos = 3
        elif filename_without_ext.startswith('##'): fixed_pos = 2
        elif filename_without_ext.startswith('#'): fixed_pos = 1
        
        if fixed_pos > 0:
            if fixed_pos in fixed_files_map:
                conflict_msg = f"å†²çª: å­˜åœ¨å¤šä¸ªæ–‡ä»¶è¯•å›¾å›ºå®šåœ¨ç¬¬ {fixed_pos} ä¸ªå›¾ç‰‡æ¥å£ ({fixed_files_map[fixed_pos]} å’Œ {f})ã€‚å·²ç¦ç”¨æ¨¡å¼äºŒã€‚"
                return sorted_all_files, [], {}, conflict_msg
            fixed_files_map[fixed_pos] = f
        else:
            sequential_files.append(f)
            
    return sorted_all_files, sequential_files, fixed_files_map, None

def handle_mode_selection(is_mode2_eligible: bool) -> int:
    """å¤„ç†äº¤äº’å¼æ¨¡å¼é€‰æ‹©ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥ 1 æˆ– 2ï¼Œæˆ–æŒ‰å›è½¦ã€‚"""
    print("\n" + "=" * 60)
    print("ğŸ“¢ å‘ç°å›ºå®šå›¾ç‰‡æ ‡è¯†ç¬¦ (# / ## / ###)ï¼Œè¯·é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
    print("=" * 60)
    print("ã€1ã€‘ æ¨¡å¼ä¸€ (é»˜è®¤/åºåˆ—æ¨¡å¼)ï¼šä½¿ç”¨è‡ªåŠ¨æ­¥é•¿å’Œé‡å å¤„ç†æ‰€æœ‰å›¾ç‰‡ã€‚")
    if is_mode2_eligible:
        print("ã€2ã€‘ æ¨¡å¼äºŒ (å›ºå®šå›¾ç‰‡æ¨¡å¼)ï¼šå°†å›ºå®šå›¾ç‰‡ä¸æ¯ä¸ªåºåˆ—å›¾ç‰‡å•ç‹¬é…å¯¹ã€‚")
        print("      - # : å›ºå®šåœ¨ API ç¬¬ 1 ä¸ªå›¾ç‰‡æ¥å£ã€‚")
        print("      - ##: å›ºå®šåœ¨ API ç¬¬ 2 ä¸ªå›¾ç‰‡æ¥å£ã€‚")
        print("      - ###: å›ºå®šåœ¨ API ç¬¬ 3 ä¸ªå›¾ç‰‡æ¥å£ã€‚")
    else:
        print("ã€2ã€‘ æ¨¡å¼äºŒ (å›ºå®šå›¾ç‰‡æ¨¡å¼)ï¼š(å½“å‰ API BATCH_SIZE ä¸æ”¯æŒï¼Œå·²ç¦ç”¨)")
    
    print("-" * 60)
    
    while True:
        try:
            user_input = input("â–¶ï¸ æ‚¨çš„é€‰æ‹© (é”®å…¥ 1 æˆ– 2ï¼Œæˆ–ç›´æ¥å›è½¦ [é»˜è®¤ 1]): ").strip()
        except Exception:
            user_input = ""

        if user_input == "" or user_input == '1':
            return 1 
        elif user_input == '2':
            if is_mode2_eligible:
                return 2
            else:
                print("   æ¨¡å¼äºŒå½“å‰ä¸é€‚ç”¨ï¼Œè¯·é€‰æ‹© 1 æˆ–æŒ‰å›è½¦ã€‚")
        else:
            print("   æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡æ–°è¾“å…¥ 1 æˆ– 2ã€‚")

def upload_image_once(image_path: str) -> Tuple[Optional[str], Optional[str]]:
    """å•æ¬¡ä¸Šä¼ å›¾ç‰‡åˆ°RunningHub"""
    global API_KEY
    if not API_KEY: return None, "API_KEY æœªè®¾ç½®"
    try:
        with open(image_path, 'rb') as f:
            files = {'file': (image_path, f, 'image/jpeg')} 
            data = {'apiKey': API_KEY}
            response = requests.post(UPLOAD_URL, data=data, files=files, timeout=30)
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    filename = result.get('data', {}).get('fileName')
                    if filename: return filename, None
        error_msg = f"ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›çŠ¶æ€ç : {response.status_code}"
        log_error("UploadFail", error_msg, {"image_path": image_path, "response_text": response.text})
        return None, error_msg
    except Exception as e:
        log_error("UploadException", str(e), {"image_path": image_path, "url": UPLOAD_URL})
        return None, str(e)

def upload_image(image_path: str) -> str:
    """ä¸Šä¼ å›¾ç‰‡åˆ°RunningHubï¼Œå¤±è´¥åè‡ªåŠ¨é‡è¯•"""
    retry_count = 0
    while True:
        if retry_count > 0: print(f"  [ç¬¬ {retry_count + 1} æ¬¡å°è¯•ä¸Šä¼ ] {image_path}")
        else: print(f"  [ä¸Šä¼ ] {image_path}")
        filename, error = upload_image_once(image_path)
        if filename:
            print(f"  âœ“ ä¸Šä¼ æˆåŠŸ: {filename}")
            return filename
        retry_count += 1
        print(f"  âœ— ä¸Šä¼ å¤±è´¥: {error}")
        if retry_count >= WORKFLOW_RETRY_COUNT:
            print(f"  è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({WORKFLOW_RETRY_COUNT})ï¼Œä¸Šä¼ å¤±è´¥ã€‚")
            raise Exception(f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {image_path}") 
        print(f"  ç­‰å¾… {RETRY_WAIT_TIME} ç§’åé‡è¯•...")
        countdown(RETRY_WAIT_TIME)

def submit_workflow(image_ids: List[Optional[str]], prompt: str) -> Tuple[Optional[str], Optional[str]]:
    """ã€åŠ¨æ€ã€‘æäº¤å·¥ä½œæµä»»åŠ¡ã€‚"""
    global WEBAPP_ID, API_KEY, WORKFLOW_NODE_TEMPLATE
    if not all([WEBAPP_ID, API_KEY, WORKFLOW_NODE_TEMPLATE]): return None, "å·¥ä½œæµé…ç½®æœªåˆå§‹åŒ–"
    
    try:
        payload = {"webappId": WEBAPP_ID, "apiKey": API_KEY, "nodeInfoList": []}
        image_idx = 0 
        for node in WORKFLOW_NODE_TEMPLATE:
            new_node = node.copy()
            
            if new_node.get("fieldName") == "image":
                if image_idx < len(image_ids) and image_ids[image_idx] is not None:
                    new_node["fieldValue"] = image_ids[image_idx]
                image_idx += 1
                
            elif new_node.get("fieldName") in ["prompt", "string", "text"] or "æç¤ºè¯" in new_node.get("description", ""):
                new_node["fieldValue"] = prompt
            
            payload["nodeInfoList"].append(new_node)

        headers = {'Host': 'www.runninghub.cn', 'Content-Type': 'application/json'}
        response = requests.post(WORKFLOW_URL, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('code') == 0:
                task_id = result.get('data', {}).get('taskId')
                if task_id: return task_id, None
        
        error_msg = f"APIè¿”å›å¼‚å¸¸ (Status: {response.status_code}, Response: {response.text[:100]}...)"
        log_error("WorkflowFail", error_msg, {"payload_snippet": json.dumps(payload)[:300], "response_text": response.text, "image_ids": image_ids})
        print(f"  âœ— æäº¤å¤±è´¥: {error_msg}")
        return None, error_msg
        
    except Exception as e:
        error_msg = str(e)
        log_error("WorkflowException", error_msg, {"url": WORKFLOW_URL, "image_ids": image_ids})
        print(f"  âœ— é”™è¯¯: {error_msg}")
        return None, error_msg

def countdown(seconds: int):
    """å€’è®¡æ—¶æ˜¾ç¤º"""
    for i in range(seconds, 0, -5):
        mins = i // 60
        secs = i % 60
        print(f"  ç­‰å¾…ä¸­... {mins:02d}:{secs:02d}", end='\r')
        time.sleep(5)
    print(" " * 30, end='\r')

# ==================== ä¸»ç¨‹åº ====================

def main():
    global WEBAPP_ID, API_KEY, WORKFLOW_NODE_TEMPLATE, BATCH_SIZE, IMAGE_STRIDE
    
    print("=" * 60)
    print("RunningHub åŠ¨æ€æ‰¹é‡å¤„ç†å·¥å…·")
    print("=" * 60)
    
    # 1. é…ç½®è§£æ
    try:
        parsed_payload = parse_curl_command(CURL_COMMAND_TEMPLATE)
        WEBAPP_ID = parsed_payload.get("webappId")
        API_KEY = parsed_payload.get("apiKey")
        WORKFLOW_NODE_TEMPLATE = parsed_payload.get("nodeInfoList")
        if not all([WEBAPP_ID, API_KEY, WORKFLOW_NODE_TEMPLATE]):
            raise ValueError("è§£æåçš„é…ç½®ç¼ºå°‘ webappId, apiKey æˆ– nodeInfoListã€‚")
        print(f"âœ“ é…ç½®è§£ææˆåŠŸï¼Webapp ID: {WEBAPP_ID}")
    except Exception as e:
        error_msg = f"é…ç½®è§£æå¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢: {e}"
        log_error("ConfigParseFatal", error_msg, {"CURL_TEMPLATE_START": CURL_COMMAND_TEMPLATE[:200]})
        print(f"\nâŒ {error_msg}")
        return
    
    # 2. ç¡®å®šå¤„ç†é€»è¾‘å’Œè·å–æ–‡ä»¶
    BATCH_SIZE, IMAGE_STRIDE = determine_processing_logic(WORKFLOW_NODE_TEMPLATE)
    print("-" * 60)
    
    all_files: List[str] = []
    current_mode = 1 # é»˜è®¤æ¨¡å¼ä¸€
    tasks = []
    
    # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘: T2I æ‰¹æ¬¡æ¨¡å¼ è¿˜æ˜¯ Image é©±åŠ¨æ¨¡å¼
    all_files, seq_files, fixed_files_map, conflict_msg = get_image_files_categorized()
    has_images = bool(all_files)
    
    # è·å–æ‰€æœ‰ TXT æ–‡ä»¶å†…å®¹ (ç”¨äº T2I æ‰¹æ¬¡è§£æ æˆ– Image æ¨¡å¼çš„é€šç”¨ Prompt)
    combined_content = get_combined_txt_content()
    
    # --- åœºæ™¯ A: T2I æ‰¹æ¬¡æ¨¡å¼ ---
    if not has_images and BATCH_SIZE == 0:
        print("\n**è¿›å…¥ T2I æ‰¹æ¬¡æ¨¡å¼**ï¼šæœªå‘ç°å›¾ç‰‡æ–‡ä»¶ï¼Œä¸” API ä¸ºçº¯æ–‡æœ¬è¾“å…¥ã€‚")
        prompt_batches = parse_prompt_batches(combined_content)
        
        if not prompt_batches:
            print("\nâŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œä¸”åœ¨ TXT æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç¬¦åˆ '=== ç»„åˆæç¤ºè¯ - NO. X ===' æ ¼å¼çš„æç¤ºè¯ç»„åˆã€‚ç¨‹åºç»ˆæ­¢ã€‚")
            return
            
        print(f"å·²è¯†åˆ«åˆ° {len(prompt_batches)} ä¸ªæç¤ºè¯ç»„åˆä»»åŠ¡ã€‚")
        
        for i, prompt in enumerate(prompt_batches):
             tasks.append({
                'image_files': [],
                'image_ids': [],
                'task_id': None,
                'status': 'pending',
                'error': None,
                'prompt': prompt, # å­˜å‚¨ç‹¬ç«‹çš„ Prompt
                'task_name': f"Prompt Batch {i+1}"
             })
        
        current_mode = 3 # æ ‡è®°ä¸º T2I æ‰¹æ¬¡æ¨¡å¼
        
    # --- åœºæ™¯ B: Image é©±åŠ¨æ¨¡å¼ (Mode 1/2) æˆ– Image API æ— å›¾ç‰‡ ---
    else:
        if BATCH_SIZE > 0 and not has_images:
            print("\nâŒ API éœ€è¦å›¾ç‰‡è¾“å…¥ (Batch Size > 0)ï¼Œä½†æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ã€‚ç¨‹åºç»ˆæ­¢ã€‚")
            return
        
        if len(all_files) < BATCH_SIZE:
            print(f"\nâŒ å›¾ç‰‡æ•°é‡ä¸è¶³ï¼å·¥ä½œæµéœ€è¦ {BATCH_SIZE} å¼ å›¾ç‰‡ï¼Œä½†åªæ‰¾åˆ° {len(all_files)} å¼ ã€‚ç¨‹åºç»ˆæ­¢ã€‚")
            return
            
        # 3. æ¨¡å¼é€‰æ‹© (ä»…åœ¨æœ‰å›¾ç‰‡ä¸” BATCH_SIZE > 0 æ—¶)
        if conflict_msg:
            print(f"âš  æ–‡ä»¶å‘½åå†²çª: {conflict_msg}")
            is_mode2_eligible = False
        else:
            num_fixed = len(fixed_files_map)
            is_mode2_eligible = num_fixed > 0 and num_fixed < BATCH_SIZE
        
        if has_images and BATCH_SIZE > 0 and is_mode2_eligible:
            current_mode = handle_mode_selection(is_mode2_eligible)
        elif BATCH_SIZE > 0 and num_fixed > 0:
            print(f"å›ºå®šå›¾ç‰‡æ•° ({num_fixed}) ä¸æ»¡è¶³ BATCH_SIZE ({BATCH_SIZE}) - 1 çš„è¦æ±‚ï¼Œè‡ªåŠ¨è¿è¡Œæ¨¡å¼ä¸€ã€‚")
            current_mode = 1
        elif BATCH_SIZE > 0:
            print("è‡ªåŠ¨è¿è¡Œæ¨¡å¼ä¸€ã€‚")
            current_mode = 1

        # 4. æ„é€ ä»»åŠ¡åˆ—è¡¨ (Mode 1/2)
        if current_mode == 1:
            i = 0
            while i + BATCH_SIZE <= len(all_files):
                current_batch_files = all_files[i : i + BATCH_SIZE]
                tasks.append({
                    'image_files': current_batch_files, 'image_ids': [None] * BATCH_SIZE, 
                    'task_id': None, 'status': 'pending', 'error': None, 'prompt': combined_content,
                    'task_name': ', '.join(current_batch_files)
                })
                i += IMAGE_STRIDE
            print(f"æ¨¡å¼ä¸€ï¼šåºåˆ—/é‡å æ¨¡å¼ã€‚å°†ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ã€‚")
        
        elif current_mode == 2:
            fixed_slots = sorted(fixed_files_map.keys())
            first_available_slot = 0
            for i in range(1, BATCH_SIZE + 1):
                if i not in fixed_slots:
                    first_available_slot = i; break

            for seq_file in seq_files:
                task_batch: List[Optional[str]] = [None] * BATCH_SIZE
                for pos, f_name in fixed_files_map.items():
                    if pos <= BATCH_SIZE: task_batch[pos - 1] = f_name
                if first_available_slot > 0: task_batch[first_available_slot - 1] = seq_file
                
                tasks.append({
                    'image_files': task_batch, 'image_ids': [None] * BATCH_SIZE, 
                    'task_id': None, 'status': 'pending', 'error': None, 'prompt': combined_content,
                    'task_name': f"Fixed + {seq_file}"
                })
            print(f"æ¨¡å¼äºŒï¼šå›ºå®šå›¾ç‰‡æ¨¡å¼ã€‚å›ºå®šæ–‡ä»¶: {fixed_files_map}ã€‚å°†ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ã€‚")
            
    # 5. æç¤ºè¯æ€»ç»“
    print("-" * 60)
    if current_mode == 3:
        print(f"[æ¨¡å¼ï¼šT2I æ‰¹æ¬¡] å°†ä½¿ç”¨ {len(prompt_batches)} ä¸ªç‹¬ç«‹æç¤ºè¯ç»„åˆã€‚")
    else:
        print(f"[æç¤ºè¯] æå–åˆ°çš„é€šç”¨ Prompt ({len(combined_content)} å­—ç¬¦): {combined_content[:100]}...")
    print("-" * 60)
            
    # 6. é€ä¸ªå¤„ç†ä»»åŠ¡
    print(f"æ¯ä¸ªä»»åŠ¡é—´éš”: {WAIT_TIME} ç§’")
    print("=" * 60)
    
    uploaded_image_ids = {}
    
    for idx, task in enumerate(tasks, 1):
        file_list = task['image_files']
        current_image_ids: List[Optional[str]] = [None] * BATCH_SIZE
        task_prompt = task['prompt']

        print(f"\n[{idx}/{len(tasks)}] ä»»åŠ¡: {task.get('task_name', 'N/A')}")
        print("-" * 60)
        
        # ä¸Šä¼ å›¾ç‰‡ (T2I æ¨¡å¼è·³è¿‡)
        if BATCH_SIZE > 0:
            try:
                for file_idx, file_name in enumerate(file_list):
                    if file_name:
                        if file_name not in uploaded_image_ids:
                            image_id = upload_image(file_name)
                            uploaded_image_ids[file_name] = image_id
                        else:
                            image_id = uploaded_image_ids[file_name]
                            print(f"  [è·³è¿‡ä¸Šä¼ ] å›¾ç‰‡ {file_name} å·²ä¸Šä¼ , ID: {image_id[:10]}...")
                        current_image_ids[file_idx] = image_id
            except Exception as e:
                task['status'] = 'upload_failed'; task['error'] = str(e)
                print(f"  âŒ ä»»åŠ¡è·³è¿‡: å›¾ç‰‡ä¸Šä¼ å‘ç”Ÿè‡´å‘½å¤±è´¥ã€‚")
                continue 
            task['image_ids'] = current_image_ids
        
        # æäº¤å·¥ä½œæµ
        if task['status'] != 'upload_failed':
            workflow_retry_count = 0
            while workflow_retry_count < WORKFLOW_RETRY_COUNT:
                if workflow_retry_count > 0: print(f"  [ç¬¬ {workflow_retry_count + 1} æ¬¡å°è¯•æäº¤å·¥ä½œæµ]")
                
                task_id, error_detail = submit_workflow(current_image_ids, task_prompt)
                
                if task_id: break
                workflow_retry_count += 1
                if workflow_retry_count < WORKFLOW_RETRY_COUNT: countdown(RETRY_WAIT_TIME)
                else: task['error'] = error_detail or 'å·¥ä½œæµæäº¤å¤±è´¥'

            if task_id:
                task['task_id'] = task_id; task['status'] = 'success'
            else:
                task['status'] = 'workflow_failed'
        
        if idx < len(tasks):
            print(f"\n  ç­‰å¾… {WAIT_TIME} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡...")
            countdown(WAIT_TIME)
    
    # 7. è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("å¤„ç†å®Œæˆï¼")
    print("=" * 60)
    
    success = [r for r in tasks if r['status'] == 'success']
    workflow_failed = [r for r in tasks if r['status'] == 'workflow_failed']
    upload_failed = [r for r in tasks if r['status'] == 'upload_failed']
    
    print(f"æˆåŠŸ: {len(success)}/{len(tasks)}")
    print(f"å·¥ä½œæµæäº¤å¤±è´¥: {len(workflow_failed)}/{len(tasks)}")
    print(f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {len(upload_failed)}/{len(tasks)}")

    results_to_save = [
        {
            'mode': current_mode,
            'task_name': r['task_name'],
            'image_files': [f or 'N/A' for f in r['image_files']] if r['image_files'] else 'çº¯æ–‡æœ¬ä»»åŠ¡',
            'status': r['status'],
            'task_id': r.get('task_id'), 
            'error': r['error']
        } for r in tasks
    ]
    with open('results_dynamic_robust.json', 'w', encoding='utf-8') as f:
        json.dump(results_to_save, f, ensure_ascii=False, indent=2)
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: results_dynamic_robust.json")
    print(f"è¯¦ç»†é”™è¯¯æ—¥å¿—å·²ä¿å­˜åˆ°: {ERROR_LOG_FILE}")
    print(f"è¯·è®¿é—® https://www.runninghub.cn/ ä¸‹è½½ç»“æœ")
    

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²å–æ¶ˆ")
    except Exception as e:
        import traceback
        log_error("UncaughtFatal", str(e), {"traceback": traceback.format_exc()})
        print(f"\nâŒ å‘ç”Ÿæœªæ•è·çš„è‡´å‘½é”™è¯¯ï¼Œè¯·æ£€æŸ¥ {ERROR_LOG_FILE}")
